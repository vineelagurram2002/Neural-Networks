{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmZjfFCnErtT8/5wxITzWB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vineelagurram2002/Neural-Networks/blob/main/seepch%20Enhncement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vCAW3_eH2sq",
        "outputId": "b6f5dfda-c69c-4d74-de91-34fc61b4d766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 150, 257])\n",
            "torch.Size([16, 150, 257])\n",
            "torch.Size([16, 150, 257])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "EPS = 1e-8\n",
        "\n",
        "def conv_insn_lrelu(in_channel, out_channel, kernel_size_in, stride_in, padding_in, insn=True, lrelu=True):\n",
        "    layers = []\n",
        "    layers.append(nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size_in, stride=stride_in, padding=padding_in))\n",
        "    if insn:\n",
        "        layers.append(nn.InstanceNorm2d(out_channel, affine=False))\n",
        "    if lrelu:\n",
        "        layers.append(nn.LeakyReLU(0.2))\n",
        "\n",
        "    layers = nn.Sequential(*layers)\n",
        "\n",
        "    return layers\n",
        "\n",
        "def convt_insn_lrelu(in_channel, out_channel, kernel_size_in, stride_in, padding_in, insn=True, lrelu=True):\n",
        "    layers = []\n",
        "    layers.append(nn.ConvTranspose2d(in_channel, out_channel, kernel_size=kernel_size_in, stride=stride_in, padding=padding_in))\n",
        "    if insn:\n",
        "        layers.append(nn.InstanceNorm2d(out_channel, affine=False))\n",
        "    if lrelu:\n",
        "        layers.append(nn.LeakyReLU(0.2))\n",
        "\n",
        "    layers = nn.Sequential(*layers)\n",
        "\n",
        "    return layers\n",
        "\n",
        "\n",
        "class EDNet_uncertainty(nn.Module):\n",
        "    def __init__(self, input_channel=1):\n",
        "        super(EDNet_uncertainty, self).__init__()\n",
        "        self.conv1 = conv_insn_lrelu(input_channel, 16, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.conv2 = conv_insn_lrelu(16, 32, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.conv3 = conv_insn_lrelu(32, 64, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.conv4 = conv_insn_lrelu(64, 128, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.conv5 = conv_insn_lrelu(128, 256, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.conv6 = conv_insn_lrelu(256, 512, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "\n",
        "        self.convt6 = convt_insn_lrelu(512, 256, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.convt5 = convt_insn_lrelu(256 + 256, 128, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.convt4 = convt_insn_lrelu(128 + 128, 64, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.convt3 = convt_insn_lrelu(64 + 64, 32, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.convt2 = convt_insn_lrelu(32 + 32, 16, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.convt1 = convt_insn_lrelu(16 + 16, 16, kernel_size_in=(5, 5), stride_in=(1, 2), padding_in=(2, 2))\n",
        "        self.convt1_mean = conv_insn_lrelu(16, out_channel=1, kernel_size_in=1, stride_in=1, padding_in=0, insn=False, lrelu=False)\n",
        "        self.convt1_logvar = conv_insn_lrelu(16, out_channel=1, kernel_size_in=1, stride_in=1, padding_in=0, insn=False, lrelu=False)\n",
        "\n",
        "    def forward(self, x, noisy_complex):\n",
        "        x = torch.unsqueeze(x, 1)  # B, 1, T, F\n",
        "        conv1 = self.conv1(x)\n",
        "        conv2 = self.conv2(conv1)\n",
        "        conv3 = self.conv3(conv2)\n",
        "        conv4 = self.conv4(conv3)\n",
        "        conv5 = self.conv5(conv4)\n",
        "        conv6 = self.conv6(conv5)\n",
        "\n",
        "        convt6 = self.convt6(conv6)\n",
        "        y = torch.cat((convt6, conv5), 1)\n",
        "\n",
        "        convt5 = self.convt5(y)\n",
        "        y = torch.cat((convt5, conv4), 1)\n",
        "\n",
        "        convt4 = self.convt4(y)\n",
        "        y = torch.cat((convt4, conv3), 1)\n",
        "\n",
        "        convt3 = self.convt3(y)\n",
        "        y = torch.cat((convt3, conv2), 1)\n",
        "\n",
        "        convt2 = self.convt2(y)\n",
        "        y = torch.cat((convt2, conv1), 1)  # B, C, T, F\n",
        "\n",
        "        convt1 = self.convt1(y)\n",
        "\n",
        "        mean = torch.sigmoid(self.convt1_mean(convt1)).squeeze()  # B x 1 x T x F -> (B) x T x F\n",
        "        logvar = self.convt1_logvar(convt1).squeeze()  # B x 1 x T x F  -> (B) x T x F\n",
        "\n",
        "        # Wiener filtering\n",
        "        WF_stft = mean * noisy_complex\n",
        "\n",
        "        # Approximated_MAP filtering\n",
        "        element = (0.5 * mean) ** 2 + torch.exp(logvar) / (4 * x.squeeze() ** 2 + EPS)\n",
        "        approximated_map = 0.5 * mean + torch.sqrt(element + EPS)\n",
        "        AMAP_stft = approximated_map * noisy_complex\n",
        "\n",
        "        return WF_stft, AMAP_stft, logvar\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Device setup\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Initialize input tensors and model, moving them to the device\n",
        "    input = torch.randn(16, 150, 257, dtype=torch.float).to(device)\n",
        "    noisy = torch.randn(16, 150, 257, dtype=torch.cfloat).to(device)\n",
        "    model = EDNet_uncertainty().to(device)\n",
        "\n",
        "    # Run the model and print output shapes\n",
        "    output = model(input, noisy)\n",
        "    print(output[0].shape)\n",
        "    print(output[1].shape)\n",
        "    print(output[2].shape)\n"
      ]
    }
  ]
}